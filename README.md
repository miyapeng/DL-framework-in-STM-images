## Deep learning framework for automated recognition of molecules in STM images
该项目完成了一种基于卷积神经网络（Convolutional Neural Network, CNN）的扫描隧道显微镜（Scanning Tunneling Microscope，STM）直写图像分类方法，用于分类STM硅基直写工艺过程中得到的图像。比起人工更为快速方便，可以处理大量的图像信息，为解决原子级量子芯片自动化加工问题提供了方案。
### 配置指南
Firstly, it is essential to ensure the download and installation of PyTorch along with the related packages. It is also important to note that due to confidentiality agreements, the STM image dataset and model weights have not been made publicly available.

To proceed with training, please execute `train_plot.py`.

For testing purposes, please run `pred.py` or `pred2.py`.

### 项目简介
扫描隧道显微镜（STM）是一种能够以亚埃级别分辨率分析表面的工具，基于量子隧穿效应。它通过扫描样品表面，记录隧道电流变化来获取表面拓扑和电子性质信息，生成高分辨率图像。STM在制作原子级量子芯片中特别重要，因为它能识别硅表面的缺陷和在直写工艺中产生的气体分子特征产物，如PH3、B2H6、BCl3等。这些信息对设计纳米结构和功能材料至关重要。然而，从STM图像中提取信息依赖于繁琐的人工分析，尤其是处理大量数据时。因此，需要自动化处理方法来解决分类问题。卷积神经网络（CNN）作为一种深度学习模型，通过卷积层提取图像特征，非常适合处理STM图像数据，实现自动分类和识别。所以该项目完成了一种基于卷积神经网络（CNN）的扫描隧道显微镜（STM）直写图像分类方法，用于分类STM硅基直写工艺过程中得到的图像。

### 项目细节
#### 执行流程
项目流程如下图1所示：
![img1](/fig/图1.png)
#### 数据集合数据增强
从扫描隧道显微镜图像数据库中获取STM直写目标典型图像样本(只要是硅缺陷合磷原子数据)，并对样本进行预处理；将获取的STM直写目标典型图像样本以预设比例分为训练集、验证集和测试集，本实施例中采用60%：20%：20%，对训练集和测试集中的样本进行数据增强处理，扩充数据集。数据集类别如下图所示：
![img](/fig/img.png)
为了获得更大的数据集，需要在扩充数据集，扩充数据集的方式有高斯噪声、椒盐噪声、乘性噪声、扩大2-10倍、缩小至0.2-0.5倍、水平翻转、垂直翻转、旋转预设角度、对比度、亮度、颜色增强、锐化和混合增强等，将原始数据集扩充了十余倍，这几种方法的扩充结果如图2所示。这些扩充数据集可以一定程度描述真实复杂的实验图片，因此，利用该数据集能很好评估STM直写目标图像智能识别算法的性能，在项目中发挥了不错的效果。
![img2](/fig/图2.png)
#### 神经网络模型搭建
在搭建模型时采用EfficientNet模型，加入Coordinate Attention（坐标注意力）模块，并结合Adam（自适应矩估计）优化算法，搭建用于STM直写目标的分类模型。模型如图3所示。输入的STM直写目标图像，经过数据增强等预处理操作转换成224像素×224像素x3通道的图像输入到EfficientNet-CA中；将第一层卷积操作后的特征图和经CA模型增强后的注意力特征图进行通道级相乘，得到具有注意力信息的特征映射；经过7个嵌有CA模块的轻量翻转瓶颈卷积层进一步提取STM直写目标图像的高层特征，得到7像素×7像素×1280通道的特征图；最后，通过全连接层得到STM直写目标图像识别的结果。
![img3](/fig/图3.png)
#### 评价与结果
本项目通过以数据集中的所有1316张图像，为试验材料，其中训练集、验证集、测试集的图像数量分别为663、332和321张图像。各类训练集、验证集、测试集包含的图像数量汇总如表1所示；

**表1 各类训练集、验证集、测试集包含的图像数量汇总**

|       | 训练集 (Training set) | 验证集 (Validation set) | 测试集 (Test set) | 合计  |
|-------|-------------------|---------------------|----------------|-----|
| 缺陷1 | 234               | 117                 | 117            | 468 |
| 缺陷2 | 234               | 117                 | 117            | 468 |
| 缺陷3 | 195               | 98                  | 87             | 380 |
| 合计  | 663               | 332                 | 321            | 1316|

在构建好上述模型后，项目在三种硅表面缺陷和P(U-shaped)、PH(Centered)、PH2(Asymmetric)三种磷原子上做了初步的测试，测试所得的结果显示如下图4所示：
![img4](/fig/图4.png)

在图4中可见构建的系统对图片进行识别，给出预测类别和预测概率(指的是系统有多少把握确定改图是该种预测类别)。由于要处理的图像较多，这里只展示一张图片，其他预测情况同理。
对模型测试的部分结果如下表2所示:

**表2 三种Si缺陷和P原子识别的正确率**

| 训练模型         | 缺陷1正确率 | 缺陷2正确率 | 缺陷3正确率 | P(U-shaped)正确率 | PH(Centered)正确率 | PH2(Asymmetric)正确率 |
|----------------|-----------|-----------|-----------|-----------------|------------------|---------------------|
| EfficientNet-CA | 100%      | 93.3%     | 100%      | 100%            | 100%             | 85.7%               |

可见该模型已具有较好的识别能力，在三种Si缺陷上具有较好的识别能力，而P原子上的识别能力仍有待加强，其中要重点加强对PH2原子的识别。这部分工作将在后续工作中持续跟进。

